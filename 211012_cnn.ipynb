{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "211012_cnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "af0e4889"
      },
      "source": [
        "import numpy as np \n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "# from google.colab import files\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score as ACC\n",
        "from PIL import Image"
      ],
      "id": "af0e4889",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ebb3282"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "id": "8ebb3282",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRR7RSRUOe9p",
        "outputId": "0e3bf4c9-4567-4d61-d037-7dfc46179096",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/mount')"
      ],
      "id": "wRR7RSRUOe9p",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /mount; to attempt to forcibly remount, call drive.mount(\"/mount\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "965ef4d6",
        "outputId": "e2462f29-ef7c-4d20-8dac-af5bb05ed0bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dir='/mount/Shareddrives/영상 드라이브/입교생 공유/11. AI이론및실습_9회차_1012/실습파일/Train/Train'\n",
        "print(len(os.listdir(train_dir)))"
      ],
      "id": "965ef4d6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "872c861f"
      },
      "source": [
        "cls_name_list=sorted(os.listdir(train_dir))\n",
        "cls_name_dict={cls_name_list[i]:i for i in range(len(cls_name_list))}"
      ],
      "id": "872c861f",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "06655a7b",
        "outputId": "c4c9e5c7-ec0e-4926-809c-f9b04f06bb14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cls_name_dict"
      ],
      "id": "06655a7b",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Alfa Romeo Stelvio': 0,\n",
              " 'Aston Martin DB11': 1,\n",
              " 'Aston Martin DBS': 2,\n",
              " 'Aston Martin Valkyrie': 3,\n",
              " 'Aston Martin Vantage': 4,\n",
              " 'Aston Martin Vulcan': 5,\n",
              " 'Audi A3': 6,\n",
              " 'Audi A6': 7,\n",
              " 'Audi E-tron GT': 8,\n",
              " 'Audi R8': 9,\n",
              " 'BMW 3-series': 10,\n",
              " 'BMW 7-series': 11,\n",
              " 'BMW x7': 12,\n",
              " 'Bentley Bentayga': 13,\n",
              " 'Bentley Continental': 14,\n",
              " 'Bugatti Centidieci': 15,\n",
              " 'Bugatti Chiron': 16,\n",
              " 'Bugatti Divo': 17,\n",
              " 'Bugatti La Voiture Noire': 18,\n",
              " 'Buggati Veyron': 19,\n",
              " 'Cadillac Escalade': 20,\n",
              " 'Corvette ZR': 21,\n",
              " 'Ferrari 458': 22,\n",
              " 'Ferrari FF': 23,\n",
              " 'Ferrari Pininfarina': 24,\n",
              " 'Jaguar F-type': 25,\n",
              " 'Jaguar XJ': 26,\n",
              " 'Koenigsegg CC8S': 27,\n",
              " 'Koenigsegg CCX': 28,\n",
              " 'La Ferrari': 29,\n",
              " 'Lamborghini Gallardo': 30,\n",
              " 'Lamborghini Murceilago': 31,\n",
              " 'Lamborghini Veneno': 32,\n",
              " 'Mustang GT': 33,\n",
              " 'Pagani Zonda': 34,\n",
              " 'Porsche 911': 35,\n",
              " 'Porsche Cayenne': 36,\n",
              " 'Range Rover Discovery': 37,\n",
              " 'Renault Duster': 38,\n",
              " 'Rolls Royce Ghost': 39,\n",
              " 'Rolls Royce Phantom': 40,\n",
              " 'Tata Tiago': 41,\n",
              " 'Toyota Fortuner': 42,\n",
              " 'Volkswagen Polo': 43,\n",
              " 'Volkswagen Vento': 44}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f008b08"
      },
      "source": [
        "image_items=[]\n",
        "for folder in os.listdir(train_dir):\n",
        "    for image in os.listdir(os.path.join(train_dir, folder)):\n",
        "        image_items.append({'image_path':os.path.join(train_dir, folder, image),\n",
        "                           'image_cls_gt': cls_name_dict[folder]})"
      ],
      "id": "1f008b08",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8f1cc9",
        "outputId": "ef8562ab-1b37-4f97-df06-926207f3f6f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "image_items[0]"
      ],
      "id": "7b8f1cc9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image_cls_gt': 9,\n",
              " 'image_path': '/mount/Shareddrives/영상 드라이브/입교생 공유/11. AI이론및실습_9회차_1012/실습파일/Train/Train/Audi R8/image14.jpg'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c27656e2"
      },
      "source": [
        "#data split\n",
        "random.shuffle(image_items)\n",
        "split_idx = int(len(image_items)*0.75)\n",
        "train_data, test_data = image_items[:split_idx], image_items[split_idx:]"
      ],
      "id": "c27656e2",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "731c99dd",
        "outputId": "d8c5f1ef-1c7b-4ff7-ff6c-e198e82ad651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_data), len(test_data), len(train_data) + len(test_data)"
      ],
      "id": "731c99dd",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3037, 1013, 4050)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab7f5dfa"
      },
      "source": [
        "# hyperparameters\n",
        "EPOCHS = 10\n",
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# augmentation\n",
        "train_aug = transforms.Compose([\n",
        "     transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(0.75, 1.33)),\n",
        "     transforms.RandomHorizontalFlip(p=0.5),\n",
        "     \n",
        "     transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.485,0.456,0.406), (0.229, 0.224,0.225))\n",
        " ])\n",
        "test_aug = transforms.Compose([\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.485,0.456,0.406), (0.229, 0.224,0.225))\n",
        " ])"
      ],
      "id": "ab7f5dfa",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8445345"
      },
      "source": [
        "class imageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, augmentation):\n",
        "        self.data = data\n",
        "        self.augmentation = augmentation\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.data[idx]['image_path']\n",
        "        gt = self.data[idx]['image_cls_gt']\n",
        "        \n",
        "        image = Image.open(image_path)\n",
        "        \n",
        "        # augmentation\n",
        "        image = self.augmentation(image)\n",
        "        gt = torch.tensor(gt).long()\n",
        "        return image, gt"
      ],
      "id": "c8445345",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f5f2471"
      },
      "source": [
        "# Data set\n",
        "train_dataset = imageDataset(train_data, train_aug)\n",
        "test_dataset = imageDataset(test_data, test_aug)\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "id": "1f5f2471",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a34b2f26"
      },
      "source": [
        "class pretrained_model(nn.Module):\n",
        "    def __init__(self, cls_size=45, pretrained=False):\n",
        "        super().__init__()\n",
        "        # self.model = torchvision.models.vgg19_bn(pretrained=pretrained)\n",
        "        # self.layer_out = nn.Linear(1000 ,cls_size)\n",
        "        # vgg19_bn.classifier\n",
        "        self.model = torchvision.models.resnet18(pretrained=pretrained)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, cls_size, bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        # out = self.layer_out(x)\n",
        "        return out"
      ],
      "id": "a34b2f26",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd4ecb55"
      },
      "source": [
        "class myModel(nn.Module):\n",
        "    def __init__(self, num_classes=45):\n",
        "        super(myModel, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(128*56*56, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.block1(x)\n",
        "        out = self.block2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "id": "dd4ecb55",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a73f8dfa"
      },
      "source": [
        "model = pretrained_model(cls_size=45, pretrained=True)\n",
        "model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/nn.html\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
      ],
      "id": "a73f8dfa",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b29acfc",
        "outputId": "d4d74928-206d-4cf0-d183-c58df35303ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 5\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(EPOCHS):\n",
        "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        X_batch = X_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        #Forward \n",
        "        y_output = model(X_batch)\n",
        "        loss = criterion(y_output, y_batch) #CELoss: The input is expected to contain raw, unnormalized scores for each class.\n",
        "        \n",
        "        #Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        #misc (acc 계산, etc) \n",
        "        y_pred = torch.max(y_output, 1)[1]\n",
        "        acc = ACC(y_batch.data.cpu(), y_pred.data.cpu())\n",
        "        loss_list.append(loss.item())\n",
        "        acc_list.append(acc)\n",
        "\n",
        "        if (i+1) % 45 == 0:\n",
        "            print('Epoch [{}/{}] Step [{}/{}] Loss: [{:.4f}] Train ACC [{:.2f}%]'.format(epoch+1, EPOCHS, \\\n",
        "                                                                                       i+1, len(train_loader), loss.item(), acc*100))"
      ],
      "id": "1b29acfc",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] Step [45/190] Loss: [2.9350] Train ACC [25.00%]\n",
            "Epoch [1/5] Step [90/190] Loss: [2.5969] Train ACC [50.00%]\n",
            "Epoch [1/5] Step [135/190] Loss: [1.9340] Train ACC [62.50%]\n",
            "Epoch [1/5] Step [180/190] Loss: [2.2273] Train ACC [31.25%]\n",
            "Epoch [2/5] Step [45/190] Loss: [1.6097] Train ACC [62.50%]\n",
            "Epoch [2/5] Step [90/190] Loss: [1.9968] Train ACC [62.50%]\n",
            "Epoch [2/5] Step [135/190] Loss: [1.7445] Train ACC [68.75%]\n",
            "Epoch [2/5] Step [180/190] Loss: [1.8408] Train ACC [50.00%]\n",
            "Epoch [3/5] Step [45/190] Loss: [1.5134] Train ACC [50.00%]\n",
            "Epoch [3/5] Step [90/190] Loss: [1.4697] Train ACC [62.50%]\n",
            "Epoch [3/5] Step [135/190] Loss: [1.1293] Train ACC [75.00%]\n",
            "Epoch [3/5] Step [180/190] Loss: [0.7311] Train ACC [87.50%]\n",
            "Epoch [4/5] Step [45/190] Loss: [1.0054] Train ACC [68.75%]\n",
            "Epoch [4/5] Step [90/190] Loss: [0.9144] Train ACC [75.00%]\n",
            "Epoch [4/5] Step [135/190] Loss: [0.9380] Train ACC [81.25%]\n",
            "Epoch [4/5] Step [180/190] Loss: [1.2580] Train ACC [62.50%]\n",
            "Epoch [5/5] Step [45/190] Loss: [1.1476] Train ACC [62.50%]\n",
            "Epoch [5/5] Step [90/190] Loss: [0.4313] Train ACC [93.75%]\n",
            "Epoch [5/5] Step [135/190] Loss: [0.9606] Train ACC [68.75%]\n",
            "Epoch [5/5] Step [180/190] Loss: [0.6624] Train ACC [81.25%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5760cee",
        "outputId": "565ea224-3633-4467-aab3-8438759866a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_acc_list = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for X_batch, y_batch in test_loader:    \n",
        "        X_batch = X_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        \n",
        "        y_output = model(X_batch)\n",
        "        y_pred = torch.max(y_output, 1)[1]\n",
        "        \n",
        "        acc = ACC(y_batch.data.cpu(), y_pred.data.cpu())\n",
        "        test_acc_list.append(acc)\n",
        "    test_acc = np.mean(test_acc_list)\n",
        "print('Test ACC: [{:.2f}%]'.format(test_acc*100))"
      ],
      "id": "e5760cee",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ACC: [81.43%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9ehj_TX07_c",
        "outputId": "0a283ffb-9cc7-4ab7-d0a4-f23cd2c75698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 5\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5)\n",
        "for epoch in range(EPOCHS):\n",
        "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        X_batch = X_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        #Forward \n",
        "        y_output = model(X_batch)\n",
        "        loss = criterion(y_output, y_batch) #CELoss: The input is expected to contain raw, unnormalized scores for each class.\n",
        "        \n",
        "        #Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        #misc (acc 계산, etc) \n",
        "        y_pred = torch.max(y_output, 1)[1]\n",
        "        acc = ACC(y_batch.data.cpu(), y_pred.data.cpu())\n",
        "        loss_list.append(loss.item())\n",
        "        acc_list.append(acc)\n",
        "\n",
        "        if (i+1) % 45 == 0:\n",
        "            print('Epoch [{}/{}] Step [{}/{}] Loss: [{:.4f}] Train ACC [{:.2f}%]'.format(epoch+1, EPOCHS, \\\n",
        "                                                                                       i+1, len(train_loader), loss.item(), acc*100))"
      ],
      "id": "B9ehj_TX07_c",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] Step [45/190] Loss: [0.6225] Train ACC [81.25%]\n",
            "Epoch [1/5] Step [90/190] Loss: [0.4664] Train ACC [87.50%]\n",
            "Epoch [1/5] Step [135/190] Loss: [0.4142] Train ACC [81.25%]\n",
            "Epoch [1/5] Step [180/190] Loss: [0.0715] Train ACC [100.00%]\n",
            "Epoch [2/5] Step [45/190] Loss: [0.6431] Train ACC [81.25%]\n",
            "Epoch [2/5] Step [90/190] Loss: [0.8889] Train ACC [68.75%]\n",
            "Epoch [2/5] Step [135/190] Loss: [0.7650] Train ACC [75.00%]\n",
            "Epoch [2/5] Step [180/190] Loss: [0.2814] Train ACC [87.50%]\n",
            "Epoch [3/5] Step [45/190] Loss: [0.3371] Train ACC [87.50%]\n",
            "Epoch [3/5] Step [90/190] Loss: [0.0851] Train ACC [100.00%]\n",
            "Epoch [3/5] Step [135/190] Loss: [0.3116] Train ACC [93.75%]\n",
            "Epoch [3/5] Step [180/190] Loss: [0.2848] Train ACC [87.50%]\n",
            "Epoch [4/5] Step [45/190] Loss: [0.3690] Train ACC [87.50%]\n",
            "Epoch [4/5] Step [90/190] Loss: [0.4547] Train ACC [87.50%]\n",
            "Epoch [4/5] Step [135/190] Loss: [0.4857] Train ACC [87.50%]\n",
            "Epoch [4/5] Step [180/190] Loss: [0.5373] Train ACC [87.50%]\n",
            "Epoch [5/5] Step [45/190] Loss: [0.5401] Train ACC [81.25%]\n",
            "Epoch [5/5] Step [90/190] Loss: [0.3956] Train ACC [87.50%]\n",
            "Epoch [5/5] Step [135/190] Loss: [0.3438] Train ACC [87.50%]\n",
            "Epoch [5/5] Step [180/190] Loss: [0.1237] Train ACC [93.75%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3143723e",
        "outputId": "c34217d2-7755-4cd8-921c-e3262474fc47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " test_acc_list = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for X_batch, y_batch in test_loader:    \n",
        "        X_batch = X_batch.cuda()\n",
        "        y_batch = y_batch.cuda()\n",
        "        \n",
        "        y_output = model(X_batch)\n",
        "        y_pred = torch.max(y_output, 1)[1]\n",
        "        \n",
        "        acc = ACC(y_batch.data.cpu(), y_pred.data.cpu())\n",
        "        test_acc_list.append(acc)\n",
        "    test_acc = np.mean(test_acc_list)\n",
        "print('Test ACC: [{:.2f}%]'.format(test_acc*100))"
      ],
      "id": "3143723e",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ACC: [84.43%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6d298e1"
      },
      "source": [
        ""
      ],
      "id": "e6d298e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7eaf4a4"
      },
      "source": [
        ""
      ],
      "id": "f7eaf4a4",
      "execution_count": null,
      "outputs": []
    }
  ]
}